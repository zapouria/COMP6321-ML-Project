{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import math\n",
    "from pysndfx import AudioEffectsChain\n",
    "import python_speech_features\n",
    "import matplotlib.pyplot as plt \n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "#Ignore unwanted warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Gender of the each speaker\n",
    "gender = {'19': 'F', '26': 'M', '27': 'M', '32':'F', '39': 'F', '40': 'F',\n",
    "          '60': 'M', '78': 'M', '83': 'F', '87':'F', '89':'F','103':'F','118':'M',\n",
    "          '125':'F','150':'F','163':'M','196':'M','198':'F','200':'F'}\n",
    "\n",
    "def read_file(loc):\n",
    "    \"\"\"\n",
    "    This function read the audio files and the outputs are sr=22050:22kHz, the sampling frequency, and x is the signal\n",
    "    \"\"\"\n",
    "    files = librosa.util.find_files(loc, ext=['wav']) \n",
    "    files = np.asarray(files)\n",
    "    return files\n",
    "\n",
    "def ambient_noise_reduction(y, sr):\n",
    "    \"\"\"\n",
    "    This function is based on the method presented on Ambient Noise Reduction in the Master thesis reference.\n",
    "    The goal is to reduce the noise which exists in the background of the environment.\n",
    "    First finds the centroids of the frames, then their minimum and maximum to use them\n",
    "    as the upper and lower thresholds respectively.\n",
    "    At the end, it decreases the gains of the noisy part of the audio.\n",
    "    \"\"\"\n",
    "    sc = librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=int(0.025 * sr), hop_length=int(0.010 * sr))\n",
    "    #This code finds the centroids of each frame with the length of 25ms and hop length of 10ms\n",
    "    upper_threshold = np.max(sc)\n",
    "    lower_threshold = np.min(sc)\n",
    "    noise_reduced = AudioEffectsChain().lowshelf(gain=-30.0, frequency=lower_threshold).highshelf(gain=-30.0, frequency=upper_threshold).limiter(gain=10.0)\n",
    "    return noise_reduced(y)\n",
    "\n",
    "def vocal_enhancement(y, sr):\n",
    "    \"\"\"\n",
    "    In this function we want to enhace the significant parts of the audio that we wish to use\n",
    "    to extract features from, and build machine learning classifiers. It will be done using concepts of MFCCs again.\n",
    "    Finding the strongest frame based on the sum square of the MFCCs coefficients, then add a gain to it.\n",
    "    \"\"\"\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr = sr,n_fft=int(0.025 * sr), hop_length=int(0.010 * sr))\n",
    "    sum_of_squares = [0] * len(mfccs)\n",
    "    for idx, val in enumerate(mfccs):\n",
    "        for d in val:\n",
    "            sum_of_squares[idx] = sum_of_squares[idx] + d**2\n",
    "\n",
    "    strongest_frame = sum_of_squares.index(max(sum_of_squares))\n",
    "    hz = python_speech_features.base.mel2hz(mfccs[strongest_frame])\n",
    "    minimum_hz = min(hz)\n",
    "    vocal_enhanced = AudioEffectsChain().lowshelf(frequency=minimum_hz*(-1), gain=10.0)\n",
    "    return vocal_enhanced(y)\n",
    "\n",
    "def audio_trimming(y, sr):\n",
    "    \"\"\"\n",
    "    This function is desiged to eliminate the silence parts of the audio, and is based on the master thesis reference.\n",
    "    we set the threshold value of 20 decibels, the frame length as 2048 and the hop length as 500.\n",
    "    \"\"\"\n",
    "    return librosa.effects.trim(y = y, top_db=20, frame_length=2048, hop_length=500)\n",
    "\n",
    "\n",
    "\n",
    "#Main\n",
    "files = read_file('./Downloads/COMP6321-ML-Project/Datasets')\n",
    "directory = './Downloads/COMP6321-ML-Project/dataset.csv'\n",
    "file_names = []\n",
    "dataset_gender = []\n",
    "data =[]\n",
    "\n",
    "\n",
    "for f in files:\n",
    "    y, sr = librosa.load(f)\n",
    "    \n",
    "    #Reduce the noise\n",
    "    y_noise_reduced = ambient_noise_reduction(y, sr)\n",
    "    \n",
    "    #Enhance the vocal enhancements\n",
    "    y_vocal_enhanced = vocal_enhancement(y_noise_reduced, sr)\n",
    "    \n",
    "    #Trim the audio\n",
    "    y_trimmed,_ = audio_trimming(y_vocal_enhanced, sr)\n",
    "\n",
    "    #Get 13 MFCC values\n",
    "    mfcc_features = librosa.feature.mfcc(y = y_trimmed, sr = sr, n_mfcc=13, hop_length=int(0.010 * sr), n_fft = int(0.025 * sr))\n",
    "\n",
    "    #Take the mean of MFCC coefficients\n",
    "    mfcc_mean= mfcc_features.mean(axis=1)\n",
    "    \n",
    "    #Get MFCC Delta\n",
    "    mfcc_delta = librosa.feature.delta(mfcc_features, order=1)\n",
    "    \n",
    "    #Take the mean of MFCC Delta coefficients\n",
    "    mfcc_delta_mean= mfcc_delta.mean(axis=1)\n",
    "\n",
    "    #Create a list of MFCC(13 columns) and MFCC Delta coefficients(13 columns) and appned it to data list\n",
    "    data.append(np.concatenate((mfcc_mean, mfcc_delta_mean)))\n",
    "    \n",
    "    #Store the name of the files to a list in order to add it to the dataframe.\n",
    "    file_names.append(f.split(\"/\")[-1].split(\"-\")[0])\n",
    "    \n",
    "    #Store the gender of the speaker to the list in order to add it to the dataframe.\n",
    "    dataset_gender.append(gender[f.split(\"/\")[-1].split(\"-\")[0]])  \n",
    "    \n",
    "    print(\"the speaker %s has been added to the list!\" % f.split(\"/\")[-1].split(\"-\")[0])\n",
    "\n",
    "#Pass the list of coefficients to the dataframe.\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "#Insert the column of the file name and the genders to the dataframe \n",
    "df.insert(0, \"file name\", file_names, True)\n",
    "df.insert(1, \"file name\", dataset_gender, True)\n",
    "\n",
    "#Save the dataframe to the CSV file.\n",
    "df.to_csv(directory, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
